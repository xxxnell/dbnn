{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models as models\n",
    "import ops.depth_estimation.datasets as datasets\n",
    "import ops.depth_estimation.trains as trains\n",
    "import ops.depth_estimation.tests as tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['figure.titlesize'] = 25\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 13\n",
    "plt.rcParams['lines.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "cwd = os.getcwd()\n",
    "model_path = 'models_checkpoints'\n",
    "dat_path = 'leaderboard/depth-estimation'\n",
    "\n",
    "# NYU Depth V2\n",
    "dataset_name = 'nyu_depth_v2'\n",
    "img_size = 480 // 2, 640 // 2\n",
    "crop_size = 480 // 2 - 30, 640 // 2 - 60\n",
    "# dataset_root = ...\n",
    "seq_root = 'G:/dataset/nyudv2/nyu_depth_v2_raw/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, _ = datasets.dataset(img_size, crop_size, flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for xs, ys in dataset_train.skip(200).batch(3).take(1):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    for i in range(3):\n",
    "        _ = axes[i][0].imshow(xs[i])\n",
    "        axes[i][0].axis('off')\n",
    "        \n",
    "        im = axes[i][1].imshow(tf.squeeze(ys, axis=-1)[i], cmap='gray', vmin=0)\n",
    "        fig.colorbar(im, ax=axes[i][1], fraction=0.035, pad=0.04)\n",
    "        axes[i][1].axis('off')\n",
    "\n",
    "        y_min, y_max = 0.0, tf.reduce_max(ys, axis=[1, 2], keepdims=True)\n",
    "        mask = tf.math.logical_and(ys > y_min, ys < y_max)\n",
    "        axes[i][2].imshow(tf.squeeze(mask, axis=-1)[i], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i][2].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "offset=(5, 0)\n",
    "dataset_seq = datasets.dataset_seq(seq_root, img_size, offset, i=4)\n",
    "dataset_test = dataset_seq.map(lambda xs, y: (xs[offset[0]], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for xs, ys in dataset_seq.batch(1).skip(5).take(1):\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(20, 4))\n",
    "    for i, ax in enumerate(axes[:-1]):\n",
    "        ax.imshow(xs[0][i])\n",
    "        ax.axis('off')\n",
    "    im = axes[-1].imshow(tf.squeeze(ys[0], axis=-1), cmap='gray', vmin=0)\n",
    "    fig.colorbar(im, ax=axes[-1], fraction=0.035, pad=0.04)\n",
    "    axes[-1].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "model = models.UNet(1, name='u-net-dnn')\n",
    "# model = models.SegNet(1, name='segnet-dnn')\n",
    "\n",
    "# BNN\n",
    "# model = models.UNet(1, rate=0.5, name='u-net-bnn')\n",
    "# model = models.SegNet(1, rate=0.5, name='segnet-bnn')\n",
    "\n",
    "# model.load_weights('%s/%s_%s' % (model_path, dataset_name, model.name + '_2')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = 'logs/gradient_tape/%s_%s/%s' % (dataset_name, model.name, current_time)\n",
    "train_log_dir = '%s/train' % log_dir\n",
    "test_log_dir = '%s/test' % log_dir\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "    \n",
    "print('Create TensorBoard Log dir: ', log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "epochtime_metric = tf.keras.metrics.Mean(name='epoch_time')\n",
    "loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
    "mse_metric = tf.keras.metrics.Mean(name='train_mse')\n",
    "nll_metric = tf.keras.metrics.Mean(name='train_nll')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_time = time.time()\n",
    "    loss, mse = trains.train_epoch(optimizer, model, dataset_train.skip(30000).take(10000), batch_size=10)\n",
    "    epochtime_metric(time.time() - batch_time)\n",
    "    loss_metric(loss)\n",
    "    mse_metric(mse)\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        template = '(%.2f sec) Epoch: %d, Loss: %.4f, MSE: %.4f'\n",
    "        print(template % (epochtime_metric.result(),\n",
    "                          epoch,\n",
    "                          loss_metric.result(),\n",
    "                          mse_metric.result()))\n",
    "        \n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', loss_metric.result(), step=epoch)\n",
    "            tf.summary.scalar('mse', mse_metric.result(), step=epoch)\n",
    "        \n",
    "        epochtime_metric.reset_states()\n",
    "        loss_metric.reset_states()\n",
    "        mse_metric.reset_states()\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        metrics = tests.test_vanilla(model,\n",
    "                                     dataset_val, batch_size=10, \n",
    "                                     cutoffs=(0.0, 0.9), verbose=False)\n",
    "        \n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('nll', metrics[0], step=epoch)\n",
    "            tf.summary.scalar('mse', metrics[1], step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('%s/%s_%s' % (model_path, dataset_name, model.name + '_5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tests.test_vanilla(model,\n",
    "                       dataset_test, batch_size=1, \n",
    "                       var=0.4, cutoffs=(0.0, 0.9), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tests.test_sampling(model, 30, \n",
    "                        dataset_test, batch_size=10, \n",
    "                        var=0.4, cutoffs=(0.0, 0.9), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tests.test_temporal_smoothing(model, 0.8, \n",
    "                                  dataset_seq, batch_size=10, \n",
    "                                  var=0.4, cutoffs=(0.0, 0.9), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for xs, ys in dataset_train.skip(10).batch(1).take(1):\n",
    "    ys_pred = tests.predict_vanilla(model, xs, var=0.05)\n",
    "    ys_pred_mean, ys_pred_var = tf.split(ys_pred, [1, 1], axis=-1)\n",
    "    \n",
    "    mse = tf.math.square(ys_pred_mean - ys)\n",
    "    rmse = tf.math.sqrt(mse)\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(16, 5))\n",
    "    axes[0].imshow(xs[0])\n",
    "    im = axes[1].imshow(tf.squeeze(ys, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[1], fraction=0.035, pad=0.04)\n",
    "    im = axes[2].imshow(tf.squeeze(ys_pred_mean, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[2], fraction=0.035, pad=0.04)\n",
    "    im = axes[3].imshow(tf.squeeze(rmse, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[3], fraction=0.035, pad=0.04)\n",
    "    im = axes[4].imshow(tf.squeeze(ys_pred_var, axis=-1)[0], vmin=0, cmap='gist_yarg')\n",
    "    fig.colorbar(im, ax=axes[4], fraction=0.035, pad=0.04)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for xs, ys in dataset_val.skip(20).batch(1).take(1):\n",
    "    ys_pred = tests.predict_sampling(model, xs, 10, var=0.05)\n",
    "    ys_pred_mean, ys_pred_var = tf.split(ys_pred, [1, 1], axis=-1)\n",
    "    \n",
    "    mse = tf.math.square(ys_pred_mean - ys)\n",
    "    rmse = tf.math.sqrt(mse)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(16, 5))\n",
    "    axes[0].imshow(xs[0])\n",
    "    im = axes[1].imshow(tf.squeeze(ys, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[1], fraction=0.035, pad=0.04)\n",
    "    im = axes[2].imshow(tf.squeeze(ys_pred_mean, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[2], fraction=0.035, pad=0.04)\n",
    "    im = axes[3].imshow(tf.squeeze(rmse, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[3], fraction=0.035, pad=0.04)\n",
    "    im = axes[4].imshow(tf.squeeze(ys_pred_var, axis=-1)[0], vmin=0, cmap='gist_yarg')\n",
    "    fig.colorbar(im, ax=axes[4], fraction=0.035, pad=0.04)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xs, ys in dataset_seq.skip(100).batch(2).take(1):\n",
    "    ys_pred = predict_temporal_smoothing(model, xs, l=0.8, var=0.05)\n",
    "    ys_pred_mean, ys_pred_var = tf.split(ys_pred, [1, 1], axis=-1)\n",
    "    \n",
    "    mse = tf.math.square(ys_pred_mean - ys)\n",
    "    rmse = tf.math.sqrt(mse)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(16, 5))\n",
    "    axes[0].imshow(xs[0][-1])\n",
    "    im = axes[1].imshow(tf.squeeze(ys, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[1], fraction=0.035, pad=0.04)\n",
    "    im = axes[2].imshow(tf.squeeze(ys_pred_mean, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[2], fraction=0.035, pad=0.04)\n",
    "    im = axes[3].imshow(tf.squeeze(rmse, axis=-1)[0], vmin=0, vmax=tf.reduce_max(ys[0]), cmap='gist_gray')\n",
    "    fig.colorbar(im, ax=axes[3], fraction=0.035, pad=0.04)\n",
    "    im = axes[4].imshow(tf.squeeze(ys_pred_var, axis=-1)[0], vmin=0, cmap='gist_yarg')\n",
    "    fig.colorbar(im, ax=axes[4], fraction=0.035, pad=0.04)\n",
    "            \n",
    "    for ax in axes:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
